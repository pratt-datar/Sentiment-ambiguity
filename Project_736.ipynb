{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path as path\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import itemfreq\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from bs4 import BeautifulSoup\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot settings\n",
    "plt.rc('font', family='serif', size = 10)\n",
    "plt.rc('figure', figsize=(15,8))\n",
    "plt.rc('xtick', labelsize=18)\n",
    "plt.rc('ytick', labelsize=18)\n",
    "plt.rc('axes', titlesize=32, labelsize=25) \n",
    "plt.rc('legend', fontsize=18) \n",
    "plt.rc('axes', titlepad=15, labelpad=15, grid=True, titleweight='normal', labelweight='normal')\n",
    "plt.rc('grid', linestyle='dashed', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "og_location = os.path.abspath(os.path.realpath(os.path.join(os.getcwd(), '..\\Data')))\n",
    "# reading train and test files\n",
    "Train = pd.read_csv(og_location + \"\\drugsComTrain_raw.csv\", encoding= \"utf-8\")\n",
    "Test = pd.read_csv(og_location + \"\\drugsComTest_raw.csv\", encoding= \"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merging train and test data for pre-processing\n",
    "merged_data = pd.concat([Train,Test],ignore_index=True)\n",
    "# remove NAs and drop duplicates\n",
    "merged_data = merged_data.dropna(axis=0).drop_duplicates()\n",
    "# remove certain condition that are useless\n",
    "span_data = merged_data[merged_data['condition'].str.contains('</span>',case=False,regex=True) == True]\n",
    "merged_data.drop(span_data.index, axis = 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to remove html characters from the data\n",
    "def remove_html(raw_review):\n",
    "    # 1. Delete HTML \n",
    "    review_text = ''.join(BeautifulSoup(raw_review, 'html.parser').get_text())\n",
    "    return (review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "review_text = merged_data['review'].apply(remove_html)\n",
    "# remove special characters\n",
    "review_text = review_text.map(lambda x: re.sub(r'[^\\w]', ' ', x))  \n",
    "# 3. remove added white spaces\n",
    "review_text = review_text.map(lambda x: re.sub(\"\\s\\s+\", \" \", x))\n",
    "# 4. remove delimiters \n",
    "X = review_text.map(lambda x: x.replace(\"\\n\",'').replace(\"\\r\",'').replace(\"\\t\", '')).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rating Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(merged_data['rating'], normed = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Percentage distribution of data \n",
    "dist = pd.DataFrame(round(merged_data.groupby(['rating']).count()['uniqueID']/len(merged_data) * 100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist.columns = ['perc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skewed data check for rating and creating target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating target labels\n",
    "y = merged_data['rating'].apply(lambda x: -1 if x < 3 else x)\n",
    "y = y.apply(lambda x: 0 if (2 < x < 9) else x)\n",
    "y = y.apply(lambda x: 1 if  x > 8 else x).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min_df  Max_df value select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def min_vectorizers():\n",
    "    min_df = []\n",
    "    for i in range(1,11):\n",
    "        vect = CountVectorizer(encoding='latin-1', lowercase = True, binary=True, min_df = i, stop_words='english')\n",
    "        vecs_count = vect.fit_transform(X_train)\n",
    "        min_df.append(vecs_count.shape[1])\n",
    "    return min_df\n",
    "\n",
    "def max_vectorizers():\n",
    "    max_df = []\n",
    "    for i in range(1,11):\n",
    "        vect = CountVectorizer(encoding='latin-1', lowercase = True, binary=True, max_df = i/10, stop_words='english')\n",
    "        vecs_count = vect.fit_transform(X_train)\n",
    "        max_df.append(vecs_count.shape[1])\n",
    "    return max_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_df = max_vectorizers()\n",
    "min_df = min_vectorizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(10,100,10), max_df)\n",
    "plt.ylabel('Vocabulary size')\n",
    "plt.xlabel('Max_df %')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1,10,10), min_df)\n",
    "plt.ylabel('Vocabulary size')\n",
    "plt.xlabel('Min_DF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# declare vectorizer\n",
    "count_vectorizer = CountVectorizer(encoding='latin-1', binary = True, lowercase = True, min_df = 3, max_df = 0.7, ngram_range = (1,2))#, stop_words=stop_list)\n",
    "# vocabulary creation\n",
    "X_train_vec = count_vectorizer.fit_transform(X_train)\n",
    "X_test_vec = count_vectorizer.transform(X_test)\n",
    "print(len(count_vectorizer.vocabulary_))\n",
    "print(\"Train Data\",X_train_vec.shape)\n",
    "print(\"Test Data\",X_test_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stopwords experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = list(stop_words.ENGLISH_STOP_WORDS)\n",
    "vocab = list(count_vectorizer.vocabulary_.items())\n",
    "stop_list = []\n",
    "for i in range(0, len(vocab)):\n",
    "    for j in range(0, len(stop)):\n",
    "        if vocab[i][0] == stop[j]:\n",
    "            if vocab[i][1] > np.ceil(len(vocab) * 0.7):\n",
    "                #print(vocab[i])\n",
    "                stop_list.append(vocab[i][0])\n",
    "stop_list = frozenset(stop_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# declare vectorizer\n",
    "count_vectorizer = CountVectorizer(encoding='latin-1', binary = True, lowercase = True, min_df = 3, max_df = 0.7, ngram_range = (1,2), stop_words=stop_list)\n",
    "# vocabulary creation\n",
    "X_train_vec = count_vectorizer.fit_transform(X_train)\n",
    "X_test_vec = count_vectorizer.transform(X_test)\n",
    "print(len(count_vectorizer.vocabulary_))\n",
    "print(\"Train Data\",X_train_vec.shape)\n",
    "print(\"Test Data\",X_test_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize the LinearSVC model\n",
    "svm_clf = LinearSVC(C=1)\n",
    "\n",
    "# use the training data to train the model\n",
    "svm_clf.fit(X_train_vec,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_clf.score(X_test_vec,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize the MNB model\n",
    "nb_clf= MultinomialNB()\n",
    "\n",
    "# use the training data to train the MNB model\n",
    "nb_clf.fit(X_train_vec,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Boolean vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bernoulliNB_clf = BernoulliNB()\n",
    "bernoulliNB_clf.fit(X_train_vec,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.round(nb_clf.score(X_test_vec,y_test) * 100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.round(bernoulliNB_clf.score(X_test_vec,y_test) * 100, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_B = bernoulliNB_clf.predict(X_test_vec)\n",
    "y_pred_mnb = nb_clf.predict(X_test_vec)\n",
    "y_pred_svm = svm_clf.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cosine similarity\n",
    "cos_sim = cosine_similarity([y_pred_B,y_pred_mnb,y_pred_svm])\n",
    "print(cos_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix and F-scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_labels = [-1,0,1]\n",
    "target_names = ['-1','0','1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred_svm, labels= target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_svm, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extreme misclassification percentage\n",
    "(confusion_matrix(y_test, y_pred_svm, labels= target_labels)[0][2] + confusion_matrix(y_test, y_pred_svm, labels= target_labels)[2][0])/len(y_test) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred_mnb, labels= target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_mnb, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extreme misclassification percentage\n",
    "(confusion_matrix(y_test, y_pred_mnb, labels= target_labels)[0][2] + confusion_matrix(y_test, y_pred_mnb, labels= target_labels)[2][0])/len(y_test) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred_B, labels= target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_B, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extreme misclassification percentage\n",
    "(confusion_matrix(y_test, y_pred_B, labels= target_labels)[0][2] + confusion_matrix(y_test, y_pred_B, labels= target_labels)[2][0])/len(y_test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Common_list in MNB, BNB,  for prediction class 1 and wrongly predicted as -1\n",
    "err_cnt = 0\n",
    "\n",
    "for i in range(0, len(y_test)):\n",
    "    if((y_test[i]==1) and (y_pred_svm[i]==-1) and (y_pred_mnb[i] == -1) and (y_pred_B[i] == -1)):\n",
    "        print(X_test[i])\n",
    "        print('-----',i)\n",
    "\n",
    "        err_cnt = err_cnt+1\n",
    "print(\"errors:\", err_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Common_list in MNB, BNB, for prediction class -1 and wrongly predicted as 1\n",
    "err_cnt = 0\n",
    "\n",
    "for i in range(0, len(y_test)):\n",
    "    if((y_test[i]== -1) and (y_pred_svm[i]==1) and (y_pred_mnb[i] == 1) and (y_pred_B[i] == 1)):\n",
    "        print(X_test[i])\n",
    "        print('-----',i)\n",
    "\n",
    "        err_cnt = err_cnt+1\n",
    "print(\"errors:\", err_cnt)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "negative_ranks = sorted(zip(svm_clf.coef_[-1], count_vectorizer.get_feature_names()))\n",
    "top_neg= []\n",
    "## get the 10 features that are best indicators of negative sentiment \n",
    "negative_10 = negative_ranks[-50:]\n",
    "print(\"Negative words\")\n",
    "for i in range(0, len(negative_10)):\n",
    "    print(negative_10[i])\n",
    "    top_neg.append(negative_10[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neutral_ranks = sorted(zip(svm_clf.coef_[0], count_vectorizer.get_feature_names()))\n",
    "top_neu= []\n",
    "## get the 10 features that are best indicators of neutral sentiment\n",
    "neutral_10 = neutral_ranks[-50:]\n",
    "print(\"Neutral words\")\n",
    "for i in range(0, len(neutral_10)):\n",
    "    print(neutral_10[i])\n",
    "    top_neu.append(neutral_10[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_ranks = sorted(zip(svm_clf.coef_[1], count_vectorizer.get_feature_names()))\n",
    "top_pos = []\n",
    "## get the 10 features that are best indicators of neutral sentiment\n",
    "positive_10 = positive_ranks[-50:]\n",
    "print(\"Positive words\")\n",
    "for i in range(0, len(positive_10)):\n",
    "    print(positive_10[i])\n",
    "    top_pos.append(positive_10[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k = (' '.join(top_pos))\n",
    "wordcloud = WordCloud(width = 1000, height = 500).generate(k)\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Checking for binary classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# declare vectorizer\n",
    "count_vectorizer = CountVectorizer(encoding='latin-1', lowercase = True, min_df = 3, max_df = 0.7, ngram_range = (1,2), stop_words=stop_list)\n",
    "class_list = []\n",
    "for i in range(2,11):\n",
    "    class_label = i\n",
    "    # creating target labels\n",
    "    y = merged_data['rating'].apply(lambda x: 0 if x == class_label else 1)\n",
    "    \n",
    "    # dividing train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "    \n",
    "    # vocabulary creation\n",
    "    X_train_vec = count_vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = count_vectorizer.transform(X_test)\n",
    "    \n",
    "    # initialize the LinearSVC model\n",
    "    svm_clf = LinearSVC(C=1)\n",
    "    \n",
    "    # use the training data to train the model\n",
    "    svm_clf.fit(X_train_vec,y_train)\n",
    "    \n",
    "    # finding top words for the respective class\n",
    "    feature_ranks = sorted(zip(svm_clf.coef_[0], count_vectorizer.get_feature_names()))\n",
    "    \n",
    "    class_words = feature_ranks[-50:]\n",
    "    \n",
    "    class_list_temp = []\n",
    "    for i in range(0, len(class_words)):\n",
    "        class_list_temp.append(class_words[i][1])\n",
    "    \n",
    "    class_list.append(class_list_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ambiguity based on conjunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conjunction_list= ['and','but','moreover','in addition','as long as','only if','when','in case','assumption','additionally','further','furthermore','along with','as well as','also','plus','if','unless','even if','even until']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mystring = ['I am going and found this but cannot go now', 'moreover i am going when i would be good just in case if i dont']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conj_count_list = []\n",
    "for i in range(0, len(X)):\n",
    "    conj_count = 0\n",
    "    for j in conjunction_list:\n",
    "        if X[i].find(j) != -1:\n",
    "            conj_count +=1\n",
    "    conj_count_list.append(conj_count)\n",
    "conj_df = {'conj_count': conj_count_list, 'y': y}\n",
    "conj_df = pd.DataFrame(data = conj_df)    \n",
    "conj_df.groupby('y').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conj_count_list = []\n",
    "for i in range(0, len(X_test)):\n",
    "    conj_count = 0\n",
    "    if((y_test[i]== -1) and (y_pred_svm[i]==1) and (y_pred_mnb[i] == 1) and (y_pred_B[i] == 1)):\n",
    "        for j in conjunction_list:\n",
    "            if X_test[i].find(j) != -1:\n",
    "                conj_count +=1\n",
    "    conj_count_list.append(conj_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(X_test)):\n",
    "    if((y_test[i]== -1) and (y_pred_svm[i]==1) and (y_pred_mnb[i] == 1) and (y_pred_B[i] == 1)):\n",
    "        print(conj_count_list[i])\n",
    "        print(X_test[i])\n",
    "        print('----------------------------------',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conj_count_list = []\n",
    "for i in range(0, len(X_test)):\n",
    "    conj_count = 0\n",
    "    if((y_test[i]== 1) and (y_pred_svm[i]== -1) and (y_pred_mnb[i] == -1) and (y_pred_B[i] == -1)):\n",
    "        for j in conjunction_list:\n",
    "            if X_test[i].find(j) != -1:\n",
    "                conj_count +=1\n",
    "    conj_count_list.append(conj_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(X_test)):\n",
    "    if((y_test[i]== 1) and (y_pred_svm[i]== -1) and (y_pred_mnb[i] == -1) and (y_pred_B[i] == -1)):\n",
    "        print(conj_count_list[i])\n",
    "        print(X_test[i])\n",
    "        print('----------------------------------',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
